{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b590945",
   "metadata": {},
   "source": [
    "\n",
    "# Siamese Network for Face Verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4243f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_lfw_pairs\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1. Build Embedding Model\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5451fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_model(embedding_dim=128):\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        include_top=False, \n",
    "        weights=\"imagenet\", \n",
    "        pooling=\"avg\", \n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "\n",
    "     # Fine-tune last layers\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:100]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    inputs = layers.Input(shape=(224,224,3))\n",
    "    x = tf.keras.applications.resnet50.preprocess_input(inputs)\n",
    "    x = base_model(x, training=True)\n",
    "\n",
    "    # Deeper embedding head\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(embedding_dim)(x)\n",
    "    x = layers.Lambda(lambda t: tf.math.l2_normalize(t, axis=1))(x)\n",
    "    \n",
    "    return models.Model(inputs, x, name=\"EmbeddingModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c89feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 2. Build Siamese Model (Distance-based)\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ed60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_model(embedding_model):\n",
    "    input_a = layers.Input(shape=(224,224,3))\n",
    "    input_b = layers.Input(shape=(224,224,3))\n",
    "\n",
    "    emb_a = embedding_model(input_a)\n",
    "    emb_b = embedding_model(input_b)\n",
    "\n",
    "    # Calculate Euclidean distance\n",
    "    distance = layers.Lambda(lambda embeddings: tf.sqrt(tf.reduce_sum(tf.square(embeddings[0] - embeddings[1]), axis=1, keepdims=True)))([emb_a, emb_b])\n",
    "\n",
    "    return models.Model([input_a, input_b], distance, name=\"SiameseNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010107e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 3. Alternative: Binary Classification Siamese Model\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf6ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_model_binary(embedding_model):\n",
    "    input_a = layers.Input(shape=(224,224,3))\n",
    "    input_b = layers.Input(shape=(224,224,3))\n",
    "\n",
    "    emb_a = embedding_model(input_a)\n",
    "    emb_b = embedding_model(input_b)\n",
    "\n",
    "    # Calculate similarity features\n",
    "    cosine_sim = layers.Dot(axes=1, normalize=True)([emb_a, emb_b])\n",
    "    cosine_sim = layers.Reshape((1,))(cosine_sim)\n",
    "    abs_diff = layers.Lambda(lambda x: tf.abs(x[0] - x[1]))([emb_a, emb_b])\n",
    "    \n",
    "    # Combine features\n",
    "    combined = layers.Concatenate()([cosine_sim, abs_diff])\n",
    "    \n",
    "    # Classification head\n",
    "    x = layers.Dense(64, activation='relu')(combined)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return models.Model([input_a, input_b], output, name=\"SiameseNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39770b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 4. Contrastive Loss for Distance-based Model\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e750297",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, margin=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.margin = margin\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # y_true: 1 for same person, 0 for different persons\n",
    "        # y_pred: euclidean distance\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        \n",
    "        # For same person (y_true=1): minimize distance\n",
    "        same_loss = y_true * tf.square(y_pred)\n",
    "        \n",
    "        # For different persons (y_true=0): maximize distance up to margin\n",
    "        diff_loss = (1 - y_true) * tf.square(tf.maximum(0.0, self.margin - y_pred))\n",
    "        \n",
    "        return tf.reduce_mean(same_loss + diff_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8ca983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 5. Data Loading and Preprocessing\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd546f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    img = tf.image.resize(img, (224,224))\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "def make_dataset(lfw_pairs):\n",
    "    X1, X2, y = lfw_pairs.pairs[:,0], lfw_pairs.pairs[:,1], lfw_pairs.target\n",
    "    X1 = np.array([preprocess(img).numpy() for img in X1])\n",
    "    X2 = np.array([preprocess(img).numpy() for img in X2])\n",
    "    y  = np.array(y).astype(\"float32\")\n",
    "    return (X1, X2), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading LFW dataset...\")\n",
    "lfw_pairs_train = fetch_lfw_pairs(subset='train', color=True, resize=0.5, download_if_missing=True)\n",
    "lfw_pairs_test  = fetch_lfw_pairs(subset='test', color=True, resize=0.5, download_if_missing=True)\n",
    "\n",
    "(train_X1, train_X2), train_y = make_dataset(lfw_pairs_train)\n",
    "(test_X1, test_X2), test_y   = make_dataset(lfw_pairs_test)\n",
    "\n",
    "print(f\"Training pairs: {len(train_y)}\")\n",
    "print(f\"Test pairs: {len(test_y)}\")\n",
    "print(\"Label distribution:\", np.unique(train_y, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee39dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 6. Build and Compile Models\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c3e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build embedding model\n",
    "embedding_model = build_embedding_model()\n",
    "\n",
    "# Option 1: Distance-based Siamese model\n",
    "print(\"Building distance-based Siamese model...\")\n",
    "siamese_model = build_siamese_model(embedding_model)\n",
    "\n",
    "# Option 2: Binary classification Siamese model (recommended)\n",
    "print(\"Building binary classification Siamese model...\")\n",
    "siamese_model_binary = build_siamese_model_binary(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ec8194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 7. Training Setup\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08904e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_siamese_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23e6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 8. Training - Choose ONE of these options\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1: Distance-based model with Contrastive Loss\n",
    "print(\"\\n=== Training Distance-based Model ===\")\n",
    "siamese_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "    loss=ContrastiveLoss(margin=1.0),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_distance = siamese_model.fit(\n",
    "    [train_X1, train_X2], train_y,\n",
    "    validation_data=([test_X1, test_X2], test_y),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58212cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2: Binary Classification Model (RECOMMENDED)\n",
    "print(\"\\n=== Training Binary Classification Model ===\")\n",
    "siamese_model_binary.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_binary = siamese_model_binary.fit(\n",
    "    [train_X1, train_X2], train_y,\n",
    "    validation_data=([test_X1, test_X2], test_y),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938832b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 9. Plotting Training History\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143229a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, title=\"Training History\"):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'{title} - Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'{title} - Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Learning rate plot\n",
    "    plt.subplot(1, 3, 3)\n",
    "    if 'learning_rate' in history.history:\n",
    "        plt.plot(history.history['learning_rate'], label='Learning Rate')\n",
    "        plt.title(f'{title} - Learning Rate')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot results for both models\n",
    "plot_training_history(history_distance, \"Distance-based Model\")\n",
    "plot_training_history(history_binary, \"Binary Classification Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8b95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 10. Model Evaluation\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3550d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_data, model_type=\"distance\"):\n",
    "    test_loss, test_acc = model.evaluate(test_data[0], test_data[1], verbose=0)\n",
    "    print(f\"\\n=== {model_type.upper()} MODEL RESULTS ===\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(test_data[0])\n",
    "    \n",
    "    if model_type == \"distance\":\n",
    "        # For distance model, threshold around 0.5\n",
    "        threshold = 0.5\n",
    "        pred_labels = (predictions.flatten() < threshold).astype(int)\n",
    "    else:\n",
    "        # For binary model, threshold at 0.5\n",
    "        threshold = 0.5\n",
    "        pred_labels = (predictions.flatten() > threshold).astype(int)\n",
    "    \n",
    "    # Calculate accuracy manually\n",
    "    correct = np.sum(pred_labels == test_data[1])\n",
    "    manual_acc = correct / len(test_data[1])\n",
    "    print(f\"Manual Accuracy: {manual_acc:.4f}\")\n",
    "    \n",
    "    return test_loss, test_acc\n",
    "\n",
    "# Evaluate both models\n",
    "evaluate_model(siamese_model, ([test_X1, test_X2], test_y), \"distance\")\n",
    "evaluate_model(siamese_model_binary, ([test_X1, test_X2], test_y), \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9c97aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 11. Inference Functions\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd04892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_faces_distance(img_path1, img_path2, model, threshold=0.5):\n",
    "    \"\"\"For distance-based model\"\"\"\n",
    "    def load_and_preprocess(path):\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = img.resize((224,224))\n",
    "        img = np.array(img).astype(\"float32\")\n",
    "        return img\n",
    "    \n",
    "    img1 = load_and_preprocess(img_path1)\n",
    "    img2 = load_and_preprocess(img_path2)\n",
    "    \n",
    "    img1 = np.expand_dims(img1, axis=0)\n",
    "    img2 = np.expand_dims(img2, axis=0)\n",
    "\n",
    "    distance = model.predict([img1, img2], verbose=0)[0][0]\n",
    "    print(f\"Distance: {distance:.4f}\")\n",
    "    \n",
    "    if distance < threshold:  # Lower distance = more similar\n",
    "        print(\"✅ Same person\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"❌ Different persons\")\n",
    "        return False\n",
    "\n",
    "def compare_faces_binary(img_path1, img_path2, model, threshold=0.5):\n",
    "    \"\"\"For binary classification model\"\"\"\n",
    "    def load_and_preprocess(path):\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = img.resize((224,224))\n",
    "        img = np.array(img).astype(\"float32\")\n",
    "        return img\n",
    "    \n",
    "    img1 = load_and_preprocess(img_path1)\n",
    "    img2 = load_and_preprocess(img_path2)\n",
    "    \n",
    "    img1 = np.expand_dims(img1, axis=0)\n",
    "    img2 = np.expand_dims(img2, axis=0)\n",
    "\n",
    "    similarity = model.predict([img1, img2], verbose=0)[0][0]\n",
    "    print(f\"Similarity: {similarity:.4f}\")\n",
    "    \n",
    "    if similarity > threshold:\n",
    "        print(\"✅ Same person\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"❌ Different persons\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a524941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 12. Save Models\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ef0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving models...\")\n",
    "siamese_model.save('siamese_distance_model.h5')\n",
    "siamese_model_binary.save('siamese_binary_model.h5')\n",
    "embedding_model.save('embedding_model.h5')\n",
    "print(\"Models saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac17b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 13. Example Usage\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00cd9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== USAGE EXAMPLES ===\")\n",
    "print(\"For distance-based model:\")\n",
    "print(\"compare_faces_distance('path1.jpg', 'path2.jpg', siamese_model)\")\n",
    "print(\"\\nFor binary classification model:\")\n",
    "print(\"compare_faces_binary('path1.jpg', 'path2.jpg', siamese_model_binary)\")\n",
    "\n",
    "print(\"\\n=== TRAINING COMPLETE ===\")\n",
    "print(\"Key improvements made:\")\n",
    "print(\"1. ✅ Fixed architecture mismatch between model output and loss function\")\n",
    "print(\"2. ✅ Added proper contrastive loss implementation\")\n",
    "print(\"3. ✅ Implemented binary classification alternative\")\n",
    "print(\"4. ✅ Added comprehensive callbacks and monitoring\")\n",
    "print(\"5. ✅ Reduced learning rate for stable training\")\n",
    "print(\"6. ✅ Added proper evaluation and inference functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0e4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\n",
    "=== TRAINING COMPLETE ===\")\n",
    "print(\"Key improvements made:\")\n",
    "print(\"1. ✅ Fixed architecture mismatch between model output and loss function\")\n",
    "print(\"2. ✅ Added proper contrastive loss implementation\")\n",
    "print(\"3. ✅ Implemented binary classification alternative\")\n",
    "print(\"4. ✅ Added comprehensive callbacks and monitoring\")\n",
    "print(\"5. ✅ Reduced learning rate for stable training\")\n",
    "print(\"6. ✅ Added proper evaluation and inference functions\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
